{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "LFrC0J_ZP2xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5n')"
      ],
      "metadata": {
        "id": "8whoGBlqP-1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_net = cv2.dnn.readNetFromCaffe('/content/deploy.prototxt', '/content/res10_300x300_ssd_iter_140000.caffemodel')\n",
        "profile_face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_profileface.xml')"
      ],
      "metadata": {
        "id": "LSFRgHrPQBZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_video_path = '/content/facenew.mp4'\n",
        "output_video_path = 'output_faces_and_bodies.mp4'"
      ],
      "metadata": {
        "id": "JJ1e3UzBQC6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(input_video_path)\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))"
      ],
      "metadata": {
        "id": "bYSl28B3QDmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(42)\n",
        "colors = [(random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)) for _ in range(100)]"
      ],
      "metadata": {
        "id": "79WtIErBQFu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame_count = 0\n",
        "person_tracker = defaultdict(lambda: None)\n",
        "next_person_id = 1"
      ],
      "metadata": {
        "id": "PpRhwgwoQKct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_iou(box1, box2):\n",
        "    x1, y1, x2, y2 = box1\n",
        "    x1_p, y1_p, x2_p, y2_p = box2\n",
        "    xi1, yi1 = max(x1, x1_p), max(y1, y1_p)\n",
        "    xi2, yi2 = min(x2, x2_p), min(y2, y2_p)\n",
        "    inter_width = max(0, xi2 - xi1)\n",
        "    inter_height = max(0, yi2 - yi1)\n",
        "    intersection = inter_width * inter_height\n",
        "    area_box1 = (x2 - x1) * (y2 - y1)\n",
        "    area_box2 = (x2_p - x1_p) * (y2_p - y1_p)\n",
        "    union = area_box1 + area_box2 - intersection\n",
        "    return intersection / union if union > 0 else 0"
      ],
      "metadata": {
        "id": "9YHAtMBDQNoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    results = model(frame)\n",
        "    persons = results.xyxy[0].cpu().numpy()\n",
        "    persons = [p for p in persons if int(p[-1]) == 0]\n",
        "\n",
        "    h, w = frame.shape[:2]\n",
        "\n",
        "    # Frontal face detection\n",
        "    blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
        "    face_net.setInput(blob)\n",
        "    face_detections = face_net.forward()\n",
        "\n",
        "    # Profile face detection\n",
        "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    profile_faces = profile_face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "    current_ids = []\n",
        "\n",
        "    for person in persons:\n",
        "        x1, y1, x2, y2, conf, cls = person\n",
        "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
        "\n",
        "        matched_id = None\n",
        "        for tracked_id, tracked_box in person_tracker.items():\n",
        "            if tracked_box is not None and calculate_iou((x1, y1, x2, y2), tracked_box) > 0.5:\n",
        "                matched_id = tracked_id\n",
        "                break\n",
        "\n",
        "        if matched_id is None:\n",
        "            matched_id = next_person_id\n",
        "            next_person_id += 1\n",
        "\n",
        "        person_tracker[matched_id] = (x1, y1, x2, y2)\n",
        "        current_ids.append(matched_id)\n",
        "\n",
        "        color = colors[matched_id % len(colors)]\n",
        "\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "        cv2.putText(frame, f\"Person \", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "        # Process frontal face detections\n",
        "        for i in range(face_detections.shape[2]):\n",
        "            confidence = face_detections[0, 0, i, 2]\n",
        "            if confidence > 0.5:\n",
        "                fx1, fy1, fx2, fy2 = face_detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "                fx1, fy1, fx2, fy2 = int(fx1), int(fy1), int(fx2), int(fy2)\n",
        "\n",
        "                if fx1 >= x1 and fy1 >= y1 and fx2 <= x2 and fy2 <= y2:\n",
        "                    cv2.rectangle(frame, (fx1, fy1), (fx2, fy2), color, 2)\n",
        "                    cv2.putText(frame, f\"Face \", (fx1, fy1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "        # Process profile face detections\n",
        "        for (px, py, pw, ph) in profile_faces:\n",
        "            if px >= x1 and py >= y1 and px + pw <= x2 and py + ph <= y2:\n",
        "                cv2.rectangle(frame, (px, py), (px + pw, py + ph), color, 2)\n",
        "                cv2.putText(frame, f\"Face \", (px, py - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "    person_tracker = {k: v for k, v in person_tracker.items() if k in current_ids}\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "    if frame_count % 30 == 0:\n",
        "        cv2_imshow(frame)\n",
        "\n",
        "    frame_count += 1"
      ],
      "metadata": {
        "id": "-Fa2dra1QTf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jac2grP0P1i7"
      },
      "outputs": [],
      "source": [
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "print(f\"Output video saved as {output_video_path}\")"
      ]
    }
  ]
}